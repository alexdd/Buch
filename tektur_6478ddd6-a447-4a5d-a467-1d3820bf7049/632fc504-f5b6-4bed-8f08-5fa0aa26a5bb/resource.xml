<?xml version="1.0" encoding="UTF-8"?><topic id="6f1d988d-2a6f-4ce7-82ab-8d7857e00610"><title id="8ab127a1-f7fa-4113-8ab7-9e0d00b2ccdd">mlcp - MarkLogic Content Pump</title><body id="c0ff5619-8a20-494b-acf6-5434b7154503"><p id="0bfad7a9-ed2d-4700-bf0f-dc1618b6fe0a">Die Content Pump für MarkLogic ist ein Java Tool[[xe1:Tools für MarkLogic;xe2:Content Pump]], das den Bulk-Import von Daten über die Kommadozeile realisiert.</p><p id="18eb8e60-9aa7-4995-a990-b2e35c3eb0f5d7e6">Das betreffende GitHub Projekt befindet sich [[link]]hier[[fn:https://github.com/marklogic/marklogic-contentpump*GitHub Projekt zur MarkLogic Content Pump]].</p><p id="36942ea0-9a85-4e60-a4a4-b1840d913432d7e8">Zur einfachen Installation kann man sich aber auch die Binaries auf den </p><p id="4a8a6f60-fb15-413a-a876-eb4f0d862e0fd7e10" href="undefined">[[link]]Developer Seiten[[fn:https://developer.marklogic.com/products/mlcp*Binaries zur Installation der MarkLogic Content Pump]] herunterladen.</p><p id="610445a5-b21f-4c12-b582-6acc8367231cd7e15">Folgendes Bash Skript benutze ich, um Daten nach MarkLogic hochzuladen:</p><pre id="f8360d4c-0956-4dd0-91ef-fae930160e97d7e14" xml:space="preserve">#!/bin/bash

set -eo pipefail

mlcp_opts="-database alex-test -host localhost -username admin -password admin"

mlcp import $mlcp_opts \
     -input_file_path input-files \
     -input_file_type aggregates \
     -aggregate_record_element chapter \
     -output_collections /chapter \
     -output_uri_prefix /chapter/ \
     -output_uri_suffix .xml</pre><p id="e296ffb3-e4e7-440a-90dc-3870dc33c0d1d7e19">Dabei werden alle Dateien im Ordner [[code:input-files]] importiert. Der Dateityp
der hochzuladenen Daten ist mit [[code:aggregates]] angegeben. Das sind XML Daten. </p><note id="73aa33c7-8082-4785-bd11-89a8e0f23cd3d7e18"><p id="bfaf1f2d-d1c7-43b9-9099-c629f74cc23cd7e22">Mehr Infos zu den Kommandozeilen-Optionen befinden sich auf der 
entsprechenden [[link]]Dokuseite[[fn:https://docs.marklogic.com/guide/mlcp/import*Dokuseite zu den Import Optionen der MarkLogic Content Pump]]
von MarkLogic. </p></note><p id="d6695868-ca0a-418e-91e2-bd91943744b3d7e24">Mit der Option [[code:-aggregate_record_element]] wird definiert, dass die Eingabe bzgl. des Elements [[code:&lt;chapter&gt;]] aufgesplittet werden soll.
D.h. eine Datei mit folgendem Inhalt: </p><pre id="e245e4f1-dbae-4910-bf69-dac9f9d39d7dd7e23" xml:space="preserve">&lt;test&gt;
  &lt;title&gt;Test Datei&lt;/title&gt;
  &lt;chapter&gt;
    &lt;title&gt;Test Kapitel 1&lt;/title&gt;
    &lt;content&gt;Kapitel Inhalt 1&lt;/content&gt;
  &lt;/chapter&gt;
  &lt;chapter&gt;
    &lt;title&gt;Test Kapitel 2&lt;/title&gt;
    &lt;content&gt;Kapitel Inhalt 2&lt;/content&gt;
  &lt;/chapter&gt;
  &lt;chapter&gt;
    &lt;title&gt;Test Kapitel 2&lt;/title&gt;
    &lt;content&gt;Kapitel Inhalt 2&lt;/content&gt;
  &lt;/chapter&gt;
&lt;/test&gt;</pre><p id="cfcdff52-44c0-48d4-aeca-1e8702ba3868d7e28">wird in drei Records aufgesplittet:</p><fig id="964971ac-f826-4b38-b346-3f439fb3de65d7e30"><title id="3e8d6ebe-3a99-4dc0-b7a6-01520366c54bd7e29">Ergebnis einer MarkLogic Content Pump Sitzung</title><desc id="d91347b0-a379-4e6b-9a3f-8e617257813ad7e31">Auf der Konsole kann man sich das Ergebnis der [[code:mlcp]] Sitzung anschauen. Es wurden - wie gewünscht - drei XML Fragmente separat in die Collection gespeichert.</desc><image id="a3437429-6985-408e-962d-acf1ff97c883d7e33" href="mlcp.png"/></fig><note id="f35293f6-0603-4c6a-96ca-e58efd5d64e3d7e34"><p id="3a383331-3738-4f70-877c-5f3e07ce9fbbd7e35">Um in MarkLogic keine Speicherpobleme zu erzeugen empfielt es sich große Dokumente, die man nur "speichern" will mit der Option [[code:-document_type binary]] zu importieren. In diesem Zusammenhang ist ebenfalls die Option [[code:-streaming true]] interessant.</p></note><p id="e3a06314-0fd4-4e03-89bd-f682a21edd8ad7e37">Ein weiterer wichtiger Punkt, der mir bei der Arbeit mit [[code:mlcp]] aufgefallen ist:</p><hazardstatement id="4e8d3923-1615-4e0f-a366-e21b288f9959d7e39" type="warning"><messagepanel id="276786bc-825b-4d65-81ab-fb91c5e30d41d7e40"><typeofhazard id="4060b4cc-94ca-4fb0-9925-c989f4d5ac94d7e41">Kommt es zu Inkonsistenzen in der Datenhaltung, mag das daran liegen, dass in verschiedenen [[code:mlcp]] Sitzungen von der gleichen Datei (gleicher Dateiname im Filesystem) importiert wurde.</typeofhazard><howtoavoid id="4ca51143-ff61-4deb-9d2b-9b5c7e2f6cd5d7e43">Es ist darauf zu achten, dass die Dateinamen eindeutig sind. Das kann zum Beispiel durch die Vergabe einer eindeutige ID im Dateinamen geschehen. Auf der Dokuseite zu den [[code:mlcp]] Optionen steht dazu folgendes:</howtoavoid><howtoavoid id="e0acd7e8-22ce-4e1c-b317-07e90affeef2d7e45"><i id="11b57515-73c0-47fa-9d16-de7276098bddd7e46">"If your aggregate URI id's are not unique, you can overwrite one document in your input set with another. Importing documents with non-unique URI id's from multiple threads can also cause deadlocks."</i></howtoavoid><howtoavoid id="2126c76e-622b-4103-bc18-1f6b912f619ed7e48"><i id="4660f4b5-751a-49a2-a10c-88f27da00f03d7e49">"The generated URIs are unique across a single import operation, but they are not globally unique. For example, if you repeatedly import data from some file /tmp/data.csv, the generated URIs will be the same each time (modulo differences in the number of documents inserted by the job)"</i></howtoavoid></messagepanel></hazardstatement></body></topic>